{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(268,)\n",
      "[38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38 38\n",
      " 38 38 38 38]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from model.pos_embedding import PositionalEmbedding, LearnablePositionalEncoding\n",
    "import numpy as np\n",
    "from model.transformer import Transformer\n",
    "import torch.nn as nn\n",
    "import utils.misc as misc\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.load('data/alzheimer/HCP_WM/Scan1/processed_data.npy')\n",
    "# count non-zero\n",
    "a = np.count_nonzero(data[0], axis=0)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n",
    "#print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randn(64, 175, 360)\n",
    "# pos_embedding = LearnablePositionalEncoding(360, 175)\n",
    "# b = pos_embedding(a)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(b.shape)\n",
    "\n",
    "def pad_sequence(data_array):\n",
    "        padding_length = 512 - data_array.shape[0]\n",
    "        if padding_length > 0:\n",
    "            padded_sequence = np.pad(data_array, ((0, padding_length), (0, 0)), \n",
    "                                     'constant', constant_values=0)\n",
    "        else:\n",
    "            # If no padding is needed, truncate the sequence\n",
    "            padded_sequence = data_array[:512]\n",
    "        return padded_sequence\n",
    "\n",
    "\n",
    "a = torch.randn(175, 360)\n",
    "a = a.numpy()\n",
    "print(a.shape)\n",
    "b = pad_sequence(a)\n",
    "attention_mask = torch.tensor((b != 0).all(axis=1), dtype=torch.long)\n",
    "b = torch.tensor(b).unsqueeze(0)\n",
    "print(b.shape)\n",
    "print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(360, 64, 2, 2)\n",
    "print(model)\n",
    "\n",
    "out = model(b, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '100206_EMOTION_LR_-MMP_BOLD_signals.csv'\n",
    "class_name = name.split('_')[1]\n",
    "print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# for files in os.listdir('G:/Huaxiu/HCP_YA/RL/'):\n",
    "#     if files.endswith('.csv'):\n",
    "#         df = pd.read_csv('G:/Huaxiu/HCP_YA/RL/'+files, sep='\\t')\n",
    "#         data = df.values\n",
    "#         print(type(data))\n",
    "#         print(data.shape)\n",
    "\n",
    "\n",
    "print(len(os.listdir('G:/Huaxiu/HCP_YA/RL/')))\n",
    "print(len(os.listdir('G:/Huaxiu/HCP_YA/LR/')))\n",
    "\n",
    "# df = pd.read_csv('G:/Huaxiu/HCP_YA/LR/100206_EMOTION_LR_-MMP_BOLD_signals.csv', sep='\\t')\n",
    "# data = df.values\n",
    "# #print(data)\n",
    "# print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in RL: 7455\n",
      "Number of files in LR: 7440\n",
      "Number of Files in RL not in LR: 24\n",
      "Number of Files in LR not in RL: 9\n",
      "Files in RL not in LR: ['462139_GAMBLING_RL_-MMP_BOLD_signals.csv', '531940_WM_RL_-MMP_BOLD_signals.csv', '195647_LANGUAGE_RL_-MMP_BOLD_signals.csv', '186949_WM_RL_-MMP_BOLD_signals.csv', '127731_WM_RL_-MMP_BOLD_signals.csv', '191437_GAMBLING_RL_-MMP_BOLD_signals.csv', '748662_SOCIAL_RL_-MMP_BOLD_signals.csv', '208630_WM_RL_-MMP_BOLD_signals.csv', '827052_EMOTION_RL_-MMP_BOLD_signals.csv', '107220_LANGUAGE_RL_-MMP_BOLD_signals.csv', '103010_SOCIAL_RL_-MMP_BOLD_signals.csv', '175540_SOCIAL_RL_-MMP_BOLD_signals.csv', '929464_EMOTION_RL_-MMP_BOLD_signals.csv', '368551_MOTOR_RL_-MMP_BOLD_signals.csv', '176744_MOTOR_RL_-MMP_BOLD_signals.csv', '729254_RELATIONAL_RL_-MMP_BOLD_signals.csv', '172635_RELATIONAL_RL_-MMP_BOLD_signals.csv', '727654_WM_RL_-MMP_BOLD_signals.csv', '578158_LANGUAGE_RL_-MMP_BOLD_signals.csv', '580347_MOTOR_RL_-MMP_BOLD_signals.csv', '177746_EMOTION_RL_-MMP_BOLD_signals.csv', '280941_MOTOR_RL_-MMP_BOLD_signals.csv', '128329_MOTOR_RL_-MMP_BOLD_signals.csv', '182840_EMOTION_RL_-MMP_BOLD_signals.csv']\n",
      "Files in LR not in RL: ['165032_WM_LR_-MMP_BOLD_signals.csv', '289555_RELATIONAL_LR_-MMP_BOLD_signals.csv', '165840_WM_LR_-MMP_BOLD_signals.csv', '809252_SOCIAL_LR_-MMP_BOLD_signals.csv', '872158_GAMBLING_LR_-MMP_BOLD_signals.csv', '685058_LANGUAGE_LR_-MMP_BOLD_signals.csv', '715647_RELATIONAL_LR_-MMP_BOLD_signals.csv', '185846_WM_LR_-MMP_BOLD_signals.csv', '937160_GAMBLING_LR_-MMP_BOLD_signals.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "rl_path = 'G:/Huaxiu/HCP_YA/RL/'\n",
    "lr_path = 'G:/Huaxiu/HCP_YA/LR/'\n",
    "\n",
    "rl_files = os.listdir(rl_path)\n",
    "lr_files = os.listdir(lr_path)\n",
    "\n",
    "rl_dict = {file.replace('_RL_', '_'): file for file in rl_files}\n",
    "lr_dict = {file.replace('_LR_', '_'): file for file in lr_files}\n",
    "\n",
    "rl_not_in_lr = set(rl_dict.keys()).difference(lr_dict.keys())\n",
    "lr_not_in_rl = set(lr_dict.keys()).difference(rl_dict.keys())\n",
    "\n",
    "different_files_rl = [rl_dict[file] for file in rl_not_in_lr]\n",
    "different_files_lr = [lr_dict[file] for file in lr_not_in_rl]\n",
    "print(\"Number of files in RL:\", len(rl_files))\n",
    "print(\"Number of files in LR:\", len(lr_files))\n",
    "print('Number of Files in RL not in LR:', len(different_files_rl))\n",
    "print('Number of Files in LR not in RL:', len(different_files_lr))\n",
    "print(\"Files in RL not in LR:\", different_files_rl)\n",
    "print(\"Files in LR not in RL:\", different_files_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data, cmap='bwr', aspect='auto')  \n",
    "plt.colorbar()  \n",
    "plt.title('Visualization')\n",
    "plt.xlabel('Feature Axis')\n",
    "plt.ylabel('Sample Axis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 268)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "root = 'G:/Huaxiu/HCP_WM'\n",
    "data = pd.read_csv(\n",
    "    'G:/Huaxiu/HCP_WM/Scan1/101.csv',\n",
    "    header = None\n",
    ").values.T\n",
    "\n",
    "# transpose data to LD\n",
    "print(data.shape)\n",
    "def pad_sequence(data_array):\n",
    "        padding_length = 512 - data_array.shape[0]\n",
    "        if padding_length > 0:\n",
    "            padded_sequence = np.pad(data_array, ((0, padding_length), (0, 0)), \n",
    "                                     'constant', constant_values=0)\n",
    "        else:\n",
    "            # If no padding is needed, truncate the sequence\n",
    "            padded_sequence = data_array[:512]\n",
    "        return padded_sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393, 933)\n",
      "(38, 268)\n",
      "(39, 268)\n",
      "(21, 268)\n",
      "(39, 268)\n",
      "(39, 268)\n",
      "(21, 268)\n",
      "(39, 268)\n",
      "(39, 268)\n",
      "(21, 268)\n",
      "(39, 268)\n",
      "(39, 268)\n",
      "12\n",
      "(512, 268)\n",
      "960\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(os.path.join(root, f'timing_scan1.csv'))\n",
    "print(labels.shape)\n",
    "\n",
    "#print(labels['101'].values.shape)\n",
    "sequence_labels = labels['101'].values\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "start = 0\n",
    "for timepoint in range(1, len(sequence_labels)):\n",
    "    if sequence_labels[timepoint] != sequence_labels[start]:\n",
    "        # Extract the sequence for the current label\n",
    "        sequence = data[start:timepoint, :]\n",
    "        print(sequence.shape)\n",
    "        # Pad the sequence\n",
    "        padded_sequence = pad_sequence(sequence)\n",
    "        sequences.append(padded_sequence)\n",
    "        labels.append(sequence_labels[start])\n",
    "        start = timepoint\n",
    "# Add the last sequence\n",
    "if start < len(sequence_labels):\n",
    "    sequence = data[start:, :]\n",
    "    padded_sequence = pad_sequence(sequence)\n",
    "    sequences.append(padded_sequence)\n",
    "    labels.append(sequence_labels[start])\n",
    "\n",
    "print(len(sequences))\n",
    "print(sequences[0].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015.csv\n",
      "1032.csv\n",
      "1037.csv\n",
      "149.csv\n",
      "209.csv\n",
      "225.csv\n",
      "294.csv\n",
      "318.csv\n",
      "394.csv\n",
      "401.csv\n",
      "454.csv\n",
      "555.csv\n",
      "576.csv\n",
      "595.csv\n",
      "640.csv\n",
      "652.csv\n",
      "680.csv\n",
      "689.csv\n",
      "707.csv\n",
      "739.csv\n",
      "747.csv\n",
      "828.csv\n",
      "869.csv\n",
      "878.csv\n",
      "910.csv\n",
      "924.csv\n",
      "982.csv\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir('G:/Huaxiu/HCP_WM/Scan1/')\n",
    "labels = pd.read_csv(os.path.join(root, f'timing_scan1.csv'))\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        index = file.split('.')[0]\n",
    "        if index not in labels.columns:\n",
    "            print(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
